{"cells":[{"cell_type":"markdown","source":["**This notebook loops through a Fabric Lakehouse table containing McDonald's reviews. It sends the reviews to Azure OpenAI using the native OpenAI endpoint in Fabric and has it categorize the reviews based on a list of categories provided while also providing sentiment.**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"1d5ee9b0-47a4-41e7-aa35-918780e31aad"},{"cell_type":"code","source":["#Specify the location of the lakehouse table to save results to\n","lakehouse_table = ''"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"0d61dc73-c24f-41eb-ab3a-22d2d6235697"},{"cell_type":"code","source":["#Install the openai library we need for this notebook\n","%pip install openai==0.28.1"],"outputs":[],"execution_count":null,"metadata":{},"id":"81b98242-7a21-4202-a54a-a32e0d24d98f"},{"cell_type":"code","source":["#Specify the categories to use seperated by a comma\n","categories = \"'Order Delivery Speed','Order Accuracy','Food Quality','Neighborhood or Location','Cleanliness','Cost','Other'\""],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"9c58b77e-cb46-456c-887c-e96f7639964a"},{"cell_type":"code","source":["#Read the reviews from the Fabric lakehouse table\n","df = spark.sql(\"SELECT * FROM Reviews_Lakehouse.mcdonalds_reviews\")\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"7e9b4847-7e6d-409c-812f-a59a8bc39142"},{"cell_type":"code","source":["import pandas as pd\n","import openai\n","import json\n","from pyspark.sql.functions import *\n","from delta.tables import *\n","\n","#This function is called to call Azure OpenAI with the prompt shown below. It takes the review for each row as a parameter.\n","def get_openai_response(review):\n","    prompt = f\"\"\"\n","    You are a restaurant review analysis bot. Given the following categories: {categories}.\n","    Respond to the user review data with a category or categories from the list that fits the review comments or just say 'other' if none of the categories fit.\n","    Only respond with the provided category names and whether the overall sentiment for the review is positive, negative, or neutral.\n","    Put the response in JSON format as shown here:\n","    . Example: 'It took 20 minutes to get my order! That is unacceptable. The food also didn't taste very good'\n","    Response: {{\"response\": {{\"categories\":\"Order Delivery Speed, Food Quality\", \"sentiment\": \"Negative\"}} \"\n","    \"\"\"\n","    try:\n","        response = openai.ChatCompletion.create(\n","            deployment_id='gpt-35-turbo',\n","            messages = [{\n","                \"role\": \"system\",\n","                \"content\": prompt\n","            },\n","            {\n","                \"role\": \"user\",\n","                \"content\": review\n","            }],\n","            temperature=0.0,\n","            max_tokens=2000,\n","            top_p=0.95,\n","            frequency_penalty=0,\n","            presence_penalty=0,\n","            stream=False,\n","            stop=None)\n","        response = response['choices'][0]['message']['content']\n","        data = json.loads(response)\n","        return data['response']['categories'], data['response']['sentiment']\n","\n","    except Exception as e:\n","        print(f\"Error: {e}\")\n","        return None, None\n","\n","#Pick only the relevant fields\n","reviews_df = df.select(\"review\",\"_unit_id\" )\n","df_pandas = reviews_df.toPandas()\n","\n","#Create some new columns in the dataframe to store the results\n","df_pandas['review_topics'], df_pandas['review_sentiment'] = zip(*df_pandas['review'].apply(get_openai_response))\n","\n","# Change back to a Spark dataframe\n","df_updates = spark.createDataFrame(df_pandas)\n","\n","# Load the data currently in the table\n","deltaTableReviews = DeltaTable.forPath(spark, lakehouse_table)\n","\n","# This does a Delta merge to update each row with the new sentiment and topics / categories \n","deltaTableReviews.alias('reviews_table') \\\n","    .merge(\n","        df_updates.alias('updates'),\n","        'reviews_table._unit_id = updates._unit_id'\n","    ) \\\n","    .whenMatchedUpdate(set = {'reviews_table.review_topics' : 'updates.review_topics', 'reviews_table.review_sentiment' : 'updates.review_sentiment'}) \\\n","    .execute()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"1a2dee70-51df-440f-94c9-95cb63eaa95c"},{"cell_type":"code","source":["#Read the new columns in the Fabric lakehouse table\n","df2 = spark.sql(\"SELECT * FROM Reviews_Lakehouse.mcdonalds_reviews LIMIT 10\")\n","display(df2)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"5c8ec8f8-2e9d-4570-998c-2cd3d38595d3"},{"cell_type":"code","source":["# If you want to write the results to another table rather than the current one, you can do that using the code below. Just provide a table name.\n","\n","delta_table_name = \"review_category_and_sentiment\"\n","df_updates.write.mode(\"overwrite\").format(\"delta\").saveAsTable(delta_table_name)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"c36b042b-d68f-4158-a122-ed44ee7f0317"}],"metadata":{"language_info":{"name":"python"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"kernel_info":{"name":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default"},"trident":{"lakehouse":{"default_lakehouse":"098b9932-65df-430d-b79c-0ad0181f2162","default_lakehouse_name":"Reviews_Lakehouse","default_lakehouse_workspace_id":"9ae66882-2572-4456-9b4e-cfdfcb0db0c3"}}},"nbformat":4,"nbformat_minor":5}