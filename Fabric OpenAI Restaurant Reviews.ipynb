{"cells":[{"cell_type":"markdown","source":["**This notebook loops through a Fabric Lakehouse table containing McDonalds reviews. It sends the reviews to Azure OpenAI using the native OpenAI endpoint in Fabric and has it categorize the reviews based on a list of categories provided while also providing sentiment**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"1d5ee9b0-47a4-41e7-aa35-918780e31aad"},{"cell_type":"code","source":["#Install the openai library we need for this notebook\n","%pip install openai==0.28.1"],"outputs":[],"execution_count":null,"metadata":{},"id":"81b98242-7a21-4202-a54a-a32e0d24d98f"},{"cell_type":"code","source":["#Specify the categories to use seperated by a comma\n","categories = \"'Order Delivery Speed','Order Accuracy', 'Food Quality', 'Neighborhood or Location', 'Cleanliness', 'Cost', 'Other'\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"251d4d35-d46d-42dc-98fb-615c5136b48b","statement_id":10,"state":"finished","livy_statement_state":"available","queued_time":"2024-02-23T23:16:49.9006679Z","session_start_time":null,"execution_start_time":"2024-02-23T23:16:52.8607843Z","execution_finish_time":"2024-02-23T23:16:53.1448979Z","parent_msg_id":"014083b6-0532-45c9-b2ee-83a1438624ec"},"text/plain":"StatementMeta(, 251d4d35-d46d-42dc-98fb-615c5136b48b, 10, Finished, Available)"},"metadata":{}}],"execution_count":2,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"9c58b77e-cb46-456c-887c-e96f7639964a"},{"cell_type":"code","source":["#Read the reviews from the Fabric lakehouse table\n","df = spark.sql(\"SELECT * FROM Reviews_Lakehouse.mcdonalds_reviews\")\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"7e9b4847-7e6d-409c-812f-a59a8bc39142"},{"cell_type":"code","source":["import pandas as pd\n","import openai\n","import json\n","from delta.tables import *\n","from pyspark.sql.functions import *\n","from delta.tables import *\n","\n","#Pick only the relevant fields\n","reviews_df = df.select(\"review\",\"_unit_id\" )\n","df_pandas = reviews_df.toPandas()\n","\n","#Create some new columns in the dataframe to store the results\n","df_pandas['review_topics'] = ' '\n","df_pandas['review_sentiment'] = ' '\n","\n","\n","#Loop through each row \n","for index, row in df_pandas.iterrows():\n","\n","    #Get the review text from the current row\n","    review = row['review']\n","    \n","\n","    #Build the prompt for Azure OpenAI\n","    prompt = f\"\"\"\n","      You are a restaurant review analysis bot. Given the following categories: {categories}.\n","      Respond to the user review data with a category or categories from the list that fits the review comments.\n","      Only respond with the provided category names and whether the overall sentiment for the review is positive, negative, or neutral.\n","      Put the response in JSON format as shown here:\n","    . Example: 'It took 20 minutes to get my order! That is unacceptable. The food also didn't taste very good'\n","      Response: {{\"response\": {{\"categories\":\"Order Delivery Speed, Food Quality\", \"sentiment\": \"Negative\"}} \"\n","    \"\"\"\n","\n","    response = openai.ChatCompletion.create(\n","        deployment_id='gpt-35-turbo', # deployment_id could be one of {gpt-35-turbo, gpt-35-turbo-16k}\n","        messages = [{\n","\t    \t\"role\": \"system\",\n","\t\t    \"content\": prompt\n","\t    },\n","\t    {\n","\t    \t\"role\": \"user\",\n","\t    \t\"content\": review\n","    }],\n","    temperature=0.0,\n","    max_tokens=2000,\n","    top_p=0.95,\n","    frequency_penalty=0,\n","    presence_penalty=0,\n","    stream=False,\n","    stop=None)\n","\n","\n","  \n","\n","    #Get the response back from Azure OpenAI and store it in a json variable\n","    response = response['choices'][0]['message']['content']\n","    data = json.loads(response)\n","\n","    # Access the responses in the JSON\n","    for item in data:\n","        categories = data['response']['categories']\n","        sentiment = data['response']['sentiment']\n","\n","    # Add the responses to the pandas dataframe\n","    df_pandas.loc[index, 'review_topics'] = categories\n","    df_pandas.loc[index, 'review_sentiment'] = sentiment\n","\n","\n","# Change back to a Spark dataframe\n","df_updates = spark.createDataFrame(df_pandas)\n","\n","# Load the data currently in the table\n","deltaTableReviews = DeltaTable.forPath(spark, 'abfss://9ae66882-2572-4456-9b4e-cfdfcb0db0c3@onelake.dfs.fabric.microsoft.com/098b9932-65df-430d-b79c-0ad0181f2162/Tables/mcdonalds_reviews')\n","\n","# This does a Delta merge to update each row with the sentiment and topics / categories \n","deltaTableReviews.alias('reviews_table') \\\n","    .merge(\n","        df_updates.alias('updates'),\n","        'reviews_table._unit_id = updates._unit_id'\n","    ) \\\n","    .whenMatchedUpdate(set = {'reviews_table.review_topics' : 'updates.review_topics', 'reviews_table.review_sentiment' : 'updates.review_sentiment'}) \\\n","    .execute()\n","\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"8e40db5b-e972-4739-9674-2d5ae3ab5111"},{"cell_type":"code","source":["#Read the reviews from the Fabric lakehouse table\n","df2 = spark.sql(\"SELECT * FROM Reviews_Lakehouse.mcdonalds_reviews LIMIT 10\")\n","display(df2)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"5c8ec8f8-2e9d-4570-998c-2cd3d38595d3"},{"cell_type":"code","source":["# If you want to write the results to another table, you can do that using the code below. Just provide a table name.\n","\n","delta_table_name = \"review_category_and_sentiment\"\n","df_updates.write.mode(\"overwrite\").format(\"delta\").saveAsTable(delta_table_name)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"c36b042b-d68f-4158-a122-ed44ee7f0317"}],"metadata":{"language_info":{"name":"python"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"kernel_info":{"name":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default"},"trident":{"lakehouse":{"default_lakehouse":"098b9932-65df-430d-b79c-0ad0181f2162","default_lakehouse_name":"Reviews_Lakehouse","default_lakehouse_workspace_id":"9ae66882-2572-4456-9b4e-cfdfcb0db0c3"}}},"nbformat":4,"nbformat_minor":5}